{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 11:39:01,853 - INFO - Starting SlopRank evaluation\n",
      "2025-01-06 11:39:01,854 - INFO - Reading prompts from prompts.csv\n",
      "2025-01-06 11:39:01,866 - INFO - Loaded 29 prompts\n",
      "2025-01-06 11:39:01,868 - INFO - Using configuration: EvalConfig(model_names=['gemini-2.0-flash-thinking-exp-1219', 'gemini-exp-1206', 'claude-3-5-sonnet-latest', 'claude-3-opus-latest', 'o1-preview', 'gpt-4o', 'deepseek-chat'], evaluation_method=1, use_subset_evaluation=True, evaluators_subset_size=3, output_dir=PosixPath('results'))\n",
      "2025-01-06 11:39:01,868 - INFO - Collecting responses...\n",
      "2025-01-06 11:39:01,869 - INFO - Processing prompt 1/29\n",
      "2025-01-06 11:39:01,869 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:39:02,989 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:39:15,052 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 13.18s - Valid response\n",
      "2025-01-06 11:39:15,558 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:39:16,020 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:39:38,884 - INFO - gemini-exp-1206 responded in 23.33s - Valid response\n",
      "2025-01-06 11:39:39,387 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:39:39,838 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:39:43,805 - INFO - claude-3-5-sonnet-latest responded in 4.42s - Valid response\n",
      "2025-01-06 11:39:44,309 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:39:45,106 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:40:01,157 - INFO - claude-3-opus-latest responded in 16.85s - Valid response\n",
      "2025-01-06 11:40:01,663 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:40:02,577 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:41:07,530 - INFO - o1-preview responded in 65.87s - Valid response\n",
      "2025-01-06 11:41:08,035 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:41:08,489 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:41:12,514 - INFO - gpt-4o responded in 4.48s - Valid response\n",
      "2025-01-06 11:41:13,016 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:41:13,895 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:41:22,686 - INFO - deepseek-chat responded in 9.67s - Valid response\n",
      "2025-01-06 11:41:23,189 - INFO - Processing prompt 2/29\n",
      "2025-01-06 11:41:23,190 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:41:25,875 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:41:39,345 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 16.15s - Valid response\n",
      "2025-01-06 11:41:39,849 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:41:40,344 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:41:59,371 - INFO - gemini-exp-1206 responded in 19.52s - Valid response\n",
      "2025-01-06 11:41:59,877 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:42:00,362 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:42:13,405 - INFO - claude-3-5-sonnet-latest responded in 13.53s - Valid response\n",
      "2025-01-06 11:42:13,911 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:42:14,593 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:42:34,202 - INFO - claude-3-opus-latest responded in 20.29s - Valid response\n",
      "2025-01-06 11:42:34,708 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:42:35,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:42:57,577 - INFO - o1-preview responded in 22.87s - Valid response\n",
      "2025-01-06 11:42:58,082 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:42:58,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:43:04,768 - INFO - gpt-4o responded in 6.69s - Valid response\n",
      "2025-01-06 11:43:05,274 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:43:06,338 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:43:15,164 - INFO - deepseek-chat responded in 9.89s - Valid response\n",
      "2025-01-06 11:43:15,668 - INFO - Processing prompt 3/29\n",
      "2025-01-06 11:43:15,671 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:43:16,178 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:43:35,709 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 20.04s - Valid response\n",
      "2025-01-06 11:43:36,212 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:43:36,844 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:43:57,944 - INFO - gemini-exp-1206 responded in 21.73s - Valid response\n",
      "2025-01-06 11:43:58,445 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:43:58,891 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:44:04,156 - INFO - claude-3-5-sonnet-latest responded in 5.71s - Valid response\n",
      "2025-01-06 11:44:04,658 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:44:05,445 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:44:22,498 - INFO - claude-3-opus-latest responded in 17.84s - Valid response\n",
      "2025-01-06 11:44:23,000 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:44:24,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:44:52,957 - INFO - o1-preview responded in 29.96s - Valid response\n",
      "2025-01-06 11:44:53,459 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:44:53,895 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:45:02,463 - INFO - gpt-4o responded in 9.00s - Valid response\n",
      "2025-01-06 11:45:02,966 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:45:04,152 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:45:11,445 - INFO - deepseek-chat responded in 8.48s - Valid response\n",
      "2025-01-06 11:45:11,949 - INFO - Processing prompt 4/29\n",
      "2025-01-06 11:45:11,949 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:45:13,023 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:45:37,936 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 25.99s - Valid response\n",
      "2025-01-06 11:45:38,441 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:45:39,393 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:47:19,900 - INFO - gemini-exp-1206 responded in 101.46s - Valid response\n",
      "2025-01-06 11:47:20,407 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:47:20,876 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:47:39,501 - INFO - claude-3-5-sonnet-latest responded in 19.09s - Valid response\n",
      "2025-01-06 11:47:40,007 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:47:40,691 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:48:06,713 - INFO - claude-3-opus-latest responded in 26.71s - Valid response\n",
      "2025-01-06 11:48:07,215 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:48:07,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:48:37,747 - INFO - o1-preview responded in 30.53s - Valid response\n",
      "2025-01-06 11:48:38,249 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:48:38,814 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:48:50,796 - INFO - gpt-4o responded in 12.55s - Valid response\n",
      "2025-01-06 11:48:51,299 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:48:52,270 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:49:16,797 - INFO - deepseek-chat responded in 25.50s - Valid response\n",
      "2025-01-06 11:49:17,302 - INFO - Processing prompt 5/29\n",
      "2025-01-06 11:49:17,303 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:49:21,478 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:49:44,147 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 26.84s - Valid response\n",
      "2025-01-06 11:49:44,648 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:49:45,485 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:50:22,186 - INFO - gemini-exp-1206 responded in 37.54s - Valid response\n",
      "2025-01-06 11:50:22,691 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:50:23,426 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:50:33,133 - INFO - claude-3-5-sonnet-latest responded in 10.44s - Valid response\n",
      "2025-01-06 11:50:33,638 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:50:34,314 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:50:58,360 - INFO - claude-3-opus-latest responded in 24.72s - Valid response\n",
      "2025-01-06 11:50:58,865 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:50:59,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:51:22,895 - INFO - o1-preview responded in 24.03s - Valid response\n",
      "2025-01-06 11:51:23,396 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:51:23,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:51:31,701 - INFO - gpt-4o responded in 8.31s - Valid response\n",
      "2025-01-06 11:51:32,211 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:51:33,654 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:51:47,855 - INFO - deepseek-chat responded in 15.64s - Valid response\n",
      "2025-01-06 11:51:48,363 - INFO - Processing prompt 6/29\n",
      "2025-01-06 11:51:48,364 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:51:48,862 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:52:01,342 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 12.98s - Valid response\n",
      "2025-01-06 11:52:01,848 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:52:03,715 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:52:15,938 - INFO - gemini-exp-1206 responded in 14.09s - Valid response\n",
      "2025-01-06 11:52:16,440 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:52:17,033 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:52:19,220 - INFO - claude-3-5-sonnet-latest responded in 2.78s - Valid response\n",
      "2025-01-06 11:52:19,727 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:52:20,481 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:52:30,112 - INFO - claude-3-opus-latest responded in 10.39s - Valid response\n",
      "2025-01-06 11:52:30,618 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:52:31,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:10,248 - INFO - o1-preview responded in 39.63s - Valid response\n",
      "2025-01-06 11:53:10,749 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:53:11,298 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:18,530 - INFO - gpt-4o responded in 7.78s - Valid response\n",
      "2025-01-06 11:53:19,031 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:53:20,219 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:23,341 - INFO - deepseek-chat responded in 4.31s - Valid response\n",
      "2025-01-06 11:53:23,847 - INFO - Processing prompt 7/29\n",
      "2025-01-06 11:53:23,848 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:53:24,386 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:32,324 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 8.48s - Valid response\n",
      "2025-01-06 11:53:32,829 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:53:34,793 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:40,713 - INFO - gemini-exp-1206 responded in 7.88s - Valid response\n",
      "2025-01-06 11:53:41,218 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:53:41,693 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:47,329 - INFO - claude-3-5-sonnet-latest responded in 6.11s - Valid response\n",
      "2025-01-06 11:53:47,834 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:53:48,472 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:53:56,203 - INFO - claude-3-opus-latest responded in 8.37s - Valid response\n",
      "2025-01-06 11:53:56,709 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:53:57,495 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:54:05,411 - INFO - o1-preview responded in 8.70s - Valid response\n",
      "2025-01-06 11:54:05,916 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:54:06,360 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:54:11,217 - INFO - gpt-4o responded in 5.30s - Valid response\n",
      "2025-01-06 11:54:11,719 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:54:12,776 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:54:17,119 - INFO - deepseek-chat responded in 5.40s - Valid response\n",
      "2025-01-06 11:54:17,621 - INFO - Processing prompt 8/29\n",
      "2025-01-06 11:54:17,622 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:54:18,110 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:54:29,148 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 11.53s - Valid response\n",
      "2025-01-06 11:54:29,656 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:54:31,163 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:54:48,717 - INFO - gemini-exp-1206 responded in 19.06s - Valid response\n",
      "2025-01-06 11:54:49,219 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:54:49,651 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:55:00,026 - INFO - claude-3-5-sonnet-latest responded in 10.81s - Valid response\n",
      "2025-01-06 11:55:00,530 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:55:01,261 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:55:15,513 - INFO - claude-3-opus-latest responded in 14.98s - Valid response\n",
      "2025-01-06 11:55:16,018 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:55:16,847 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:56:02,987 - INFO - o1-preview responded in 46.97s - Valid response\n",
      "2025-01-06 11:56:03,492 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:56:04,033 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:56:16,088 - INFO - gpt-4o responded in 12.60s - Valid response\n",
      "2025-01-06 11:56:16,596 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:56:17,545 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:56:28,868 - INFO - deepseek-chat responded in 12.27s - Valid response\n",
      "2025-01-06 11:56:29,370 - INFO - Processing prompt 9/29\n",
      "2025-01-06 11:56:29,373 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:56:29,916 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:56:42,655 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 13.28s - Valid response\n",
      "2025-01-06 11:56:43,158 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:56:44,054 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:56:55,421 - INFO - gemini-exp-1206 responded in 12.26s - Valid response\n",
      "2025-01-06 11:56:55,925 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:56:56,401 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:57:06,295 - INFO - claude-3-5-sonnet-latest responded in 10.37s - Valid response\n",
      "2025-01-06 11:57:06,801 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:57:07,523 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:57:25,316 - INFO - claude-3-opus-latest responded in 18.51s - Valid response\n",
      "2025-01-06 11:57:25,817 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:57:27,595 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:57:57,067 - INFO - o1-preview responded in 31.25s - Valid response\n",
      "2025-01-06 11:57:57,569 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:57:58,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:58:04,495 - INFO - gpt-4o responded in 6.93s - Valid response\n",
      "2025-01-06 11:58:04,998 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:58:05,847 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:58:12,820 - INFO - deepseek-chat responded in 7.82s - Valid response\n",
      "2025-01-06 11:58:13,326 - INFO - Processing prompt 10/29\n",
      "2025-01-06 11:58:13,327 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 11:58:13,879 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:58:27,565 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 14.24s - Valid response\n",
      "2025-01-06 11:58:28,072 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 11:58:28,529 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:58:43,577 - INFO - gemini-exp-1206 responded in 15.51s - Valid response\n",
      "2025-01-06 11:58:44,084 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 11:58:44,511 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:58:51,911 - INFO - claude-3-5-sonnet-latest responded in 7.83s - Valid response\n",
      "2025-01-06 11:58:52,413 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 11:58:53,040 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:59:13,699 - INFO - claude-3-opus-latest responded in 21.29s - Valid response\n",
      "2025-01-06 11:59:14,210 - INFO - Querying o1-preview...\n",
      "2025-01-06 11:59:14,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:59:24,252 - INFO - o1-preview responded in 10.04s - Valid response\n",
      "2025-01-06 11:59:24,757 - INFO - Querying gpt-4o...\n",
      "2025-01-06 11:59:25,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 11:59:42,342 - INFO - gpt-4o responded in 17.58s - Valid response\n",
      "2025-01-06 11:59:42,849 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 11:59:43,815 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:00:12,976 - INFO - deepseek-chat responded in 30.13s - Valid response\n",
      "2025-01-06 12:00:13,482 - INFO - Processing prompt 11/29\n",
      "2025-01-06 12:00:13,482 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:00:14,932 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:00:37,723 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 24.24s - Valid response\n",
      "2025-01-06 12:00:38,230 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:00:38,894 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:01:09,625 - INFO - gemini-exp-1206 responded in 31.40s - Valid response\n",
      "2025-01-06 12:01:10,132 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:01:10,809 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:01:17,284 - INFO - claude-3-5-sonnet-latest responded in 7.15s - Valid response\n",
      "2025-01-06 12:01:17,788 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:01:18,521 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:01:35,815 - INFO - claude-3-opus-latest responded in 18.03s - Valid response\n",
      "2025-01-06 12:01:36,321 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:01:37,011 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:02:10,435 - INFO - o1-preview responded in 34.11s - Valid response\n",
      "2025-01-06 12:02:10,941 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:02:11,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:02:28,991 - INFO - gpt-4o responded in 18.05s - Valid response\n",
      "2025-01-06 12:02:29,497 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:02:30,875 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:02:45,649 - INFO - deepseek-chat responded in 16.15s - Valid response\n",
      "2025-01-06 12:02:46,155 - INFO - Processing prompt 12/29\n",
      "2025-01-06 12:02:46,161 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:02:46,658 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:03:04,028 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 17.87s - Valid response\n",
      "2025-01-06 12:03:04,532 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:03:05,378 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:03:52,595 - INFO - gemini-exp-1206 responded in 48.06s - Valid response\n",
      "2025-01-06 12:03:53,097 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:03:53,554 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:03:58,323 - INFO - claude-3-5-sonnet-latest responded in 5.23s - Valid response\n",
      "2025-01-06 12:03:58,828 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:03:59,705 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:04:14,077 - INFO - claude-3-opus-latest responded in 15.25s - Valid response\n",
      "2025-01-06 12:04:14,582 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:04:15,404 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:04:47,799 - INFO - o1-preview responded in 33.22s - Valid response\n",
      "2025-01-06 12:04:48,305 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:04:48,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:05:02,020 - INFO - gpt-4o responded in 13.72s - Valid response\n",
      "2025-01-06 12:05:02,526 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:05:03,387 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:05:16,578 - INFO - deepseek-chat responded in 14.05s - Valid response\n",
      "2025-01-06 12:05:17,084 - INFO - Processing prompt 13/29\n",
      "2025-01-06 12:05:17,087 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:05:17,635 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:05:31,542 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 14.45s - Valid response\n",
      "2025-01-06 12:05:32,043 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:05:33,256 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:05:50,695 - INFO - gemini-exp-1206 responded in 18.65s - Valid response\n",
      "2025-01-06 12:05:51,198 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:05:51,677 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:05:55,792 - INFO - claude-3-5-sonnet-latest responded in 4.59s - Valid response\n",
      "2025-01-06 12:05:56,299 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:05:57,155 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:06:13,566 - INFO - claude-3-opus-latest responded in 17.27s - Valid response\n",
      "2025-01-06 12:06:14,073 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:06:14,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:07:26,489 - INFO - o1-preview responded in 72.42s - Valid response\n",
      "2025-01-06 12:07:26,995 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:07:27,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:07:40,401 - INFO - gpt-4o responded in 13.41s - Valid response\n",
      "2025-01-06 12:07:40,908 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:07:42,161 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:07:54,086 - INFO - deepseek-chat responded in 13.18s - Valid response\n",
      "2025-01-06 12:07:54,589 - INFO - Processing prompt 14/29\n",
      "2025-01-06 12:07:54,592 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:07:55,221 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:08:07,187 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 12.59s - Valid response\n",
      "2025-01-06 12:08:07,695 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:08:08,001 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 500 Internal Server Error\"\n",
      "2025-01-06 12:08:08,004 - ERROR - Error from gemini-exp-1206 after 0.31s: An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "2025-01-06 12:08:08,510 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:08:09,049 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:08:12,802 - INFO - claude-3-5-sonnet-latest responded in 4.29s - Valid response\n",
      "2025-01-06 12:08:13,308 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:08:14,079 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:08:24,981 - INFO - claude-3-opus-latest responded in 11.67s - Valid response\n",
      "2025-01-06 12:08:25,489 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:08:26,203 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:08:40,184 - INFO - o1-preview responded in 14.69s - Valid response\n",
      "2025-01-06 12:08:40,689 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:08:41,072 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:08:50,439 - INFO - gpt-4o responded in 9.75s - Valid response\n",
      "2025-01-06 12:08:50,941 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:08:52,152 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:09:02,247 - INFO - deepseek-chat responded in 11.31s - Valid response\n",
      "2025-01-06 12:09:02,754 - INFO - Processing prompt 15/29\n",
      "2025-01-06 12:09:02,759 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:09:03,302 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:09:22,120 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 19.36s - Valid response\n",
      "2025-01-06 12:09:22,626 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:09:24,655 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:09:54,621 - INFO - gemini-exp-1206 responded in 32.00s - Valid response\n",
      "2025-01-06 12:09:55,127 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:09:55,745 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:09:57,779 - INFO - claude-3-5-sonnet-latest responded in 2.65s - Valid response\n",
      "2025-01-06 12:09:58,283 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:09:59,088 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:10:17,077 - INFO - claude-3-opus-latest responded in 18.79s - Valid response\n",
      "2025-01-06 12:10:17,583 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:10:20,678 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:11:25,449 - INFO - o1-preview responded in 67.87s - Valid response\n",
      "2025-01-06 12:11:25,952 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:11:26,454 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:11:43,422 - INFO - gpt-4o responded in 17.47s - Valid response\n",
      "2025-01-06 12:11:43,924 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:11:45,276 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:12:01,381 - INFO - deepseek-chat responded in 17.46s - Valid response\n",
      "2025-01-06 12:12:01,887 - INFO - Processing prompt 16/29\n",
      "2025-01-06 12:12:01,888 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:12:02,426 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:12:15,218 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 13.33s - Valid response\n",
      "2025-01-06 12:12:15,724 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:12:16,733 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:12:32,318 - INFO - gemini-exp-1206 responded in 16.59s - Valid response\n",
      "2025-01-06 12:12:32,825 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:12:33,245 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:12:40,803 - INFO - claude-3-5-sonnet-latest responded in 7.98s - Valid response\n",
      "2025-01-06 12:12:41,305 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:12:42,201 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:12:57,429 - INFO - claude-3-opus-latest responded in 16.12s - Valid response\n",
      "2025-01-06 12:12:57,932 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:12:58,734 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:13:13,307 - INFO - o1-preview responded in 15.38s - Valid response\n",
      "2025-01-06 12:13:13,813 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:13:14,403 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:13:17,019 - INFO - gpt-4o responded in 3.21s - Valid response\n",
      "2025-01-06 12:13:17,525 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:13:18,506 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:13:24,260 - INFO - deepseek-chat responded in 6.73s - Valid response\n",
      "2025-01-06 12:13:24,765 - INFO - Processing prompt 17/29\n",
      "2025-01-06 12:13:24,766 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:13:25,462 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:13:48,280 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 23.51s - Valid response\n",
      "2025-01-06 12:13:48,784 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:13:49,323 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:14:46,205 - INFO - gemini-exp-1206 responded in 57.42s - Valid response\n",
      "2025-01-06 12:14:46,711 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:14:47,386 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:15:00,889 - INFO - claude-3-5-sonnet-latest responded in 14.18s - Valid response\n",
      "2025-01-06 12:15:01,393 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:15:02,054 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:15:31,533 - INFO - claude-3-opus-latest responded in 30.14s - Valid response\n",
      "2025-01-06 12:15:32,039 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:15:32,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:16:10,708 - INFO - o1-preview responded in 38.67s - Valid response\n",
      "2025-01-06 12:16:11,215 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:16:11,761 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:16:26,431 - INFO - gpt-4o responded in 15.22s - Valid response\n",
      "2025-01-06 12:16:26,937 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:16:28,001 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:16:48,717 - INFO - deepseek-chat responded in 21.78s - Valid response\n",
      "2025-01-06 12:16:49,221 - INFO - Processing prompt 18/29\n",
      "2025-01-06 12:16:49,222 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:16:49,776 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:16:59,880 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 10.66s - Valid response\n",
      "2025-01-06 12:17:00,383 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:17:01,721 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:17:22,062 - INFO - gemini-exp-1206 responded in 21.68s - Valid response\n",
      "2025-01-06 12:17:22,568 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:17:23,142 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:17:27,977 - INFO - claude-3-5-sonnet-latest responded in 5.41s - Valid response\n",
      "2025-01-06 12:17:28,482 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:17:29,123 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:17:45,244 - INFO - claude-3-opus-latest responded in 16.76s - Valid response\n",
      "2025-01-06 12:17:45,747 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:17:46,653 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:17:55,779 - INFO - o1-preview responded in 10.03s - Valid response\n",
      "2025-01-06 12:17:56,283 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:17:56,756 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:18:13,588 - INFO - gpt-4o responded in 17.30s - Valid response\n",
      "2025-01-06 12:18:14,093 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:18:14,950 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:18:22,927 - INFO - deepseek-chat responded in 8.83s - Valid response\n",
      "2025-01-06 12:18:23,431 - INFO - Processing prompt 19/29\n",
      "2025-01-06 12:18:23,432 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:18:24,165 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:18:33,809 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 10.38s - Valid response\n",
      "2025-01-06 12:18:34,312 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:18:35,259 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:18:51,682 - INFO - gemini-exp-1206 responded in 17.37s - Valid response\n",
      "2025-01-06 12:18:52,187 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:18:56,989 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:19:01,266 - INFO - claude-3-5-sonnet-latest responded in 9.08s - Valid response\n",
      "2025-01-06 12:19:01,767 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:19:03,892 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:19:14,464 - INFO - claude-3-opus-latest responded in 12.70s - Valid response\n",
      "2025-01-06 12:19:14,968 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:19:15,672 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:19:26,504 - INFO - o1-preview responded in 11.54s - Valid response\n",
      "2025-01-06 12:19:27,009 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:19:27,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:19:30,494 - INFO - gpt-4o responded in 3.48s - Valid response\n",
      "2025-01-06 12:19:30,996 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:19:32,007 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:19:35,934 - INFO - deepseek-chat responded in 4.94s - Valid response\n",
      "2025-01-06 12:19:36,440 - INFO - Processing prompt 20/29\n",
      "2025-01-06 12:19:36,440 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:19:36,971 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:19:48,589 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 12.15s - Valid response\n",
      "2025-01-06 12:19:49,095 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:19:50,487 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:20:03,695 - INFO - gemini-exp-1206 responded in 14.60s - Valid response\n",
      "2025-01-06 12:20:04,199 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:20:04,829 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:20:07,190 - INFO - claude-3-5-sonnet-latest responded in 2.99s - Valid response\n",
      "2025-01-06 12:20:07,699 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:20:08,511 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:20:21,006 - INFO - claude-3-opus-latest responded in 13.31s - Valid response\n",
      "2025-01-06 12:20:21,508 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:20:22,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:20:40,444 - INFO - o1-preview responded in 18.94s - Valid response\n",
      "2025-01-06 12:20:40,950 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:20:44,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:20:58,567 - INFO - gpt-4o responded in 17.62s - Valid response\n",
      "2025-01-06 12:20:59,071 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:21:00,225 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:21:07,203 - INFO - deepseek-chat responded in 8.13s - Valid response\n",
      "2025-01-06 12:21:07,709 - INFO - Processing prompt 21/29\n",
      "2025-01-06 12:21:07,710 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:21:08,314 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:21:21,752 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 14.04s - Valid response\n",
      "2025-01-06 12:21:22,258 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:21:23,882 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:21:46,015 - INFO - gemini-exp-1206 responded in 23.76s - Valid response\n",
      "2025-01-06 12:21:46,521 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:21:47,432 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:22:02,155 - INFO - claude-3-5-sonnet-latest responded in 15.63s - Valid response\n",
      "2025-01-06 12:22:02,662 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:22:04,738 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:22:20,590 - INFO - claude-3-opus-latest responded in 17.93s - Valid response\n",
      "2025-01-06 12:22:21,099 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:22:22,256 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:22:36,024 - INFO - o1-preview responded in 14.92s - Valid response\n",
      "2025-01-06 12:22:36,525 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:22:37,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:22:49,284 - INFO - gpt-4o responded in 12.76s - Valid response\n",
      "2025-01-06 12:22:49,790 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:22:51,066 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:23:03,945 - INFO - deepseek-chat responded in 14.16s - Valid response\n",
      "2025-01-06 12:23:04,449 - INFO - Processing prompt 22/29\n",
      "2025-01-06 12:23:04,450 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:23:05,049 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:23:34,013 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 29.56s - Valid response\n",
      "2025-01-06 12:23:34,518 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:23:35,529 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:24:31,399 - INFO - gemini-exp-1206 responded in 56.88s - Valid response\n",
      "2025-01-06 12:24:31,902 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:24:32,371 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:24:37,851 - INFO - claude-3-5-sonnet-latest responded in 5.95s - Valid response\n",
      "2025-01-06 12:24:38,356 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:24:39,156 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:24:57,835 - INFO - claude-3-opus-latest responded in 19.48s - Valid response\n",
      "2025-01-06 12:24:58,338 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:24:59,151 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:25:18,923 - INFO - o1-preview responded in 20.58s - Valid response\n",
      "2025-01-06 12:25:19,428 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:25:19,976 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:25:28,393 - INFO - gpt-4o responded in 8.96s - Valid response\n",
      "2025-01-06 12:25:28,898 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:25:30,255 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:25:48,756 - INFO - deepseek-chat responded in 19.86s - Valid response\n",
      "2025-01-06 12:25:49,260 - INFO - Processing prompt 23/29\n",
      "2025-01-06 12:25:49,260 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:25:49,815 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:25:59,327 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 10.07s - Valid response\n",
      "2025-01-06 12:25:59,832 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:26:00,463 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:26:15,312 - INFO - gemini-exp-1206 responded in 15.48s - Valid response\n",
      "2025-01-06 12:26:15,817 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:26:16,441 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:26:20,177 - INFO - claude-3-5-sonnet-latest responded in 4.36s - Valid response\n",
      "2025-01-06 12:26:20,679 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:26:21,456 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:26:30,142 - INFO - claude-3-opus-latest responded in 9.46s - Valid response\n",
      "2025-01-06 12:26:30,647 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:26:31,390 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:26:44,035 - INFO - o1-preview responded in 13.39s - Valid response\n",
      "2025-01-06 12:26:44,538 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:26:45,111 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:26:48,586 - INFO - gpt-4o responded in 4.05s - Valid response\n",
      "2025-01-06 12:26:49,087 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:26:49,808 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:26:55,461 - INFO - deepseek-chat responded in 6.37s - Valid response\n",
      "2025-01-06 12:26:55,966 - INFO - Processing prompt 24/29\n",
      "2025-01-06 12:26:55,966 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:26:56,580 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:27:04,635 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 8.67s - Valid response\n",
      "2025-01-06 12:27:05,143 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:27:07,021 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:27:11,735 - INFO - gemini-exp-1206 responded in 6.59s - Valid response\n",
      "2025-01-06 12:27:12,241 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:27:12,968 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:27:15,295 - INFO - claude-3-5-sonnet-latest responded in 3.05s - Valid response\n",
      "2025-01-06 12:27:15,798 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:27:16,751 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:27:20,519 - INFO - claude-3-opus-latest responded in 4.72s - Valid response\n",
      "2025-01-06 12:27:21,025 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:27:22,383 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:03,552 - INFO - o1-preview responded in 42.53s - Valid response\n",
      "2025-01-06 12:28:04,056 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:28:04,578 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:07,066 - INFO - gpt-4o responded in 3.01s - Valid response\n",
      "2025-01-06 12:28:07,573 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:28:08,620 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:12,233 - INFO - deepseek-chat responded in 4.66s - Valid response\n",
      "2025-01-06 12:28:12,737 - INFO - Processing prompt 25/29\n",
      "2025-01-06 12:28:12,738 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:28:13,687 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:17,924 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 5.19s - Valid response\n",
      "2025-01-06 12:28:18,428 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:28:20,202 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:22,542 - INFO - gemini-exp-1206 responded in 4.11s - Valid response\n",
      "2025-01-06 12:28:23,048 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:28:23,488 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:24,065 - INFO - claude-3-5-sonnet-latest responded in 1.02s - Valid response\n",
      "2025-01-06 12:28:24,572 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:28:25,292 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:31,051 - INFO - claude-3-opus-latest responded in 6.48s - Valid response\n",
      "2025-01-06 12:28:31,555 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:28:32,733 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:51,381 - INFO - o1-preview responded in 19.83s - Valid response\n",
      "2025-01-06 12:28:51,883 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:28:52,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:53,210 - INFO - gpt-4o responded in 1.33s - Valid response\n",
      "2025-01-06 12:28:53,715 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:28:54,736 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:28:56,702 - INFO - deepseek-chat responded in 2.99s - Valid response\n",
      "2025-01-06 12:28:57,207 - INFO - Processing prompt 26/29\n",
      "2025-01-06 12:28:57,208 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:28:57,717 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:02,011 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 4.80s - Valid response\n",
      "2025-01-06 12:29:02,514 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:29:03,555 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:04,067 - INFO - gemini-exp-1206 responded in 1.55s - Valid response\n",
      "2025-01-06 12:29:04,573 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:29:05,096 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:06,619 - INFO - claude-3-5-sonnet-latest responded in 2.05s - Valid response\n",
      "2025-01-06 12:29:07,123 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:29:07,855 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:08,902 - INFO - claude-3-opus-latest responded in 1.78s - Valid response\n",
      "2025-01-06 12:29:09,408 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:29:10,140 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:20,682 - INFO - o1-preview responded in 11.27s - Valid response\n",
      "2025-01-06 12:29:21,188 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:29:21,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:21,775 - INFO - gpt-4o responded in 0.59s - Valid response\n",
      "2025-01-06 12:29:22,279 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:29:23,385 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:24,537 - INFO - deepseek-chat responded in 2.26s - Valid response\n",
      "2025-01-06 12:29:25,043 - INFO - Processing prompt 27/29\n",
      "2025-01-06 12:29:25,044 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:29:25,580 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:29:39,615 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 14.57s - Valid response\n",
      "2025-01-06 12:29:40,117 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:29:41,020 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:30:07,903 - INFO - gemini-exp-1206 responded in 27.79s - Valid response\n",
      "2025-01-06 12:30:08,406 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:30:08,918 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:30:13,366 - INFO - claude-3-5-sonnet-latest responded in 4.96s - Valid response\n",
      "2025-01-06 12:30:13,871 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:30:14,564 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:30:32,863 - INFO - claude-3-opus-latest responded in 18.99s - Valid response\n",
      "2025-01-06 12:30:33,369 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:30:34,454 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:30:49,022 - INFO - o1-preview responded in 15.65s - Valid response\n",
      "2025-01-06 12:30:49,528 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:30:49,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:31:04,318 - INFO - gpt-4o responded in 14.79s - Valid response\n",
      "2025-01-06 12:31:04,824 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:31:05,968 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:31:18,538 - INFO - deepseek-chat responded in 13.71s - Valid response\n",
      "2025-01-06 12:31:19,043 - INFO - Processing prompt 28/29\n",
      "2025-01-06 12:31:19,044 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:31:19,643 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:31:36,007 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 16.96s - Valid response\n",
      "2025-01-06 12:31:36,512 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:31:37,079 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:32:00,222 - INFO - gemini-exp-1206 responded in 23.71s - Valid response\n",
      "2025-01-06 12:32:00,725 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:32:01,214 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:32:13,812 - INFO - claude-3-5-sonnet-latest responded in 13.09s - Valid response\n",
      "2025-01-06 12:32:14,318 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:32:15,136 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:32:40,488 - INFO - claude-3-opus-latest responded in 26.17s - Valid response\n",
      "2025-01-06 12:32:40,994 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:32:41,762 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:32:54,783 - INFO - o1-preview responded in 13.79s - Valid response\n",
      "2025-01-06 12:32:55,287 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:32:55,686 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:33:06,174 - INFO - gpt-4o responded in 10.89s - Valid response\n",
      "2025-01-06 12:33:06,680 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:33:07,823 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:33:24,323 - INFO - deepseek-chat responded in 17.64s - Valid response\n",
      "2025-01-06 12:33:24,829 - INFO - Processing prompt 29/29\n",
      "2025-01-06 12:33:24,830 - INFO - Querying gemini-2.0-flash-thinking-exp-1219...\n",
      "2025-01-06 12:33:25,347 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:33:37,773 - INFO - gemini-2.0-flash-thinking-exp-1219 responded in 12.94s - Valid response\n",
      "2025-01-06 12:33:38,276 - INFO - Querying gemini-exp-1206...\n",
      "2025-01-06 12:33:38,794 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:33:53,291 - INFO - gemini-exp-1206 responded in 15.02s - Valid response\n",
      "2025-01-06 12:33:53,796 - INFO - Querying claude-3-5-sonnet-latest...\n",
      "2025-01-06 12:33:54,307 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:34:01,289 - INFO - claude-3-5-sonnet-latest responded in 7.49s - Valid response\n",
      "2025-01-06 12:34:01,796 - INFO - Querying claude-3-opus-latest...\n",
      "2025-01-06 12:34:02,509 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:34:20,679 - INFO - claude-3-opus-latest responded in 18.88s - Valid response\n",
      "2025-01-06 12:34:21,187 - INFO - Querying o1-preview...\n",
      "2025-01-06 12:34:21,981 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:34:21,981 - ERROR - Error from o1-preview after 0.79s: Invalid prompt: your prompt was flagged as potentially violating our usage policy. Please try again with a different prompt: https://platform.openai.com/docs/guides/reasoning/advice-on-prompting\n",
      "2025-01-06 12:34:22,483 - INFO - Querying gpt-4o...\n",
      "2025-01-06 12:34:23,482 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:34:51,324 - INFO - gpt-4o responded in 28.84s - Valid response\n",
      "2025-01-06 12:34:51,830 - INFO - Querying deepseek-chat...\n",
      "2025-01-06 12:34:52,727 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:05,687 - INFO - deepseek-chat responded in 13.86s - Valid response\n",
      "2025-01-06 12:35:06,193 - INFO - All responses collected in 3364.32s\n",
      "2025-01-06 12:35:06,232 - INFO - Saved responses to results/responses.csv\n",
      "2025-01-06 12:35:06,232 - INFO - Evaluating responses...\n",
      "2025-01-06 12:35:06,968 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:10,019 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:35:11,267 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:13,095 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:16,129 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:17,986 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:29,899 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:31,030 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:32,255 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:40,445 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:42,807 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:45,692 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:35:48,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:27,041 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:28,371 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:30,008 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:34,808 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:36,665 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:39,838 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:36:42,622 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:10,663 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:12,227 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:13,633 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:17,522 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:37:18,955 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:21,443 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:25,501 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:36,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:47,932 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:50,154 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:51,517 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:55,720 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:37:56,335 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:37:58,584 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:01,348 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:03,710 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:30,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:32,096 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:33,347 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:34,581 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:38:35,123 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:37,420 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:40,222 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:42,728 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:54,959 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:57,271 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:38:58,487 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:05,276 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:08,626 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:11,599 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:13,851 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:25,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:26,649 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:27,795 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:28,804 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:39:33,009 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:35,324 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:40,784 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:39:46,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:00,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:01,587 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:03,081 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:04,905 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:40:06,485 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:08,096 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:10,330 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:12,187 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:34,089 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:35,656 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:36,918 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:37,812 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:40:39,248 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:41,963 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:44,570 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:40:46,630 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:17,230 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:18,779 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:20,115 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:24,097 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:41:25,034 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:29,227 - ERROR - Error parsing evaluation: float() argument must be a string or a real number, not 'dict'\n",
      "2025-01-06 12:41:31,684 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:33,595 - ERROR - Error parsing evaluation: float() argument must be a string or a real number, not 'dict'\n",
      "2025-01-06 12:41:36,040 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:37,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:54,535 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:57,627 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:41:58,877 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:00,097 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:42:00,713 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:04,437 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:07,491 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:10,129 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:23,390 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:24,664 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:26,055 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:28,768 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:42:29,450 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:32,294 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:34,288 - ERROR - Error parsing evaluation: float() argument must be a string or a real number, not 'dict'\n",
      "2025-01-06 12:42:36,605 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:48,153 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:58,216 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:42:59,743 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:01,483 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:04,575 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:43:05,280 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:07,612 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:10,114 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:12,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:37,221 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:38,950 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:40,284 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:44,997 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:43:46,267 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:48,000 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:50,084 - ERROR - Error parsing evaluation: float() argument must be a string or a real number, not 'dict'\n",
      "2025-01-06 12:43:52,628 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:43:55,146 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:20,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:22,175 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:23,882 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:25,276 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:44:26,447 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:28,206 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:30,621 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:32,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:45,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:47,385 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:48,766 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:50,860 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:44:51,881 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:55,562 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:44:58,665 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:09,390 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:27,016 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:29,601 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:31,111 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:32,637 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:45:33,344 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:35,664 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:39,185 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:45:40,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:21,355 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:22,656 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:24,034 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:26,671 - ERROR - Error parsing evaluation: Extra data: line 8 column 4 (char 122)\n",
      "2025-01-06 12:46:27,263 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:29,103 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:31,885 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:34,068 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:46,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:47,920 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:49,105 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:50,926 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:46:51,587 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:53,219 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:55,775 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:46:57,887 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:27,652 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:29,322 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:30,487 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:32,859 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:47:34,448 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:36,345 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:39,910 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:47:51,658 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:07,421 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:08,959 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:10,725 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:13,491 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:48:14,217 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:16,251 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:20,140 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:24,461 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:45,653 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:47,790 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:49,017 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:50,697 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:48:52,634 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:54,928 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:48:57,733 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:00,117 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:20,058 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:21,806 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:23,077 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:26,340 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:31,014 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:33,508 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:35,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:56,509 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:58,256 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:49:59,594 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:00,881 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:50:02,759 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:05,054 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:07,389 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:09,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:31,954 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:33,553 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:34,634 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:37,803 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:50:38,370 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:50:39,436 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:50:39,438 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:50:39,676 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:50:39,678 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:50:40,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:00,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:01,860 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:03,233 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:05,078 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:51:06,471 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:07,469 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:51:07,471 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:51:07,697 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:51:07,698 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:51:08,705 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:32,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:33,804 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:35,094 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:36,303 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:51:37,212 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:38,163 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:51:38,164 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:51:38,415 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:51:38,416 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:51:39,733 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:51:59,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:02,244 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:03,281 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-1219:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:07,218 - ERROR - Error parsing evaluation: No JSON object found\n",
      "2025-01-06 12:52:10,586 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:streamGenerateContent \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:11,919 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:52:11,921 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:52:12,121 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n",
      "2025-01-06 12:52:12,122 - ERROR - Error during evaluation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "2025-01-06 12:52:13,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:46,700 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:48,345 - INFO - HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-06 12:52:49,113 - INFO - Evaluation completed in 4427.26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Rankings ===\n",
      "o1-preview                     0.1592 (normalized: 10.00)\n",
      "deepseek-chat                  0.1489 (normalized: 9.35)\n",
      "gemini-exp-1206                0.1447 (normalized: 9.09)\n",
      "gemini-2.0-flash-thinking-exp-1219 0.1397 (normalized: 8.77)\n",
      "claude-3-opus-latest           0.1375 (normalized: 8.64)\n",
      "gpt-4o                         0.1373 (normalized: 8.62)\n",
      "claude-3-5-sonnet-latest       0.1326 (normalized: 8.33)\n"
     ]
    }
   ],
   "source": [
    "# SlopRank\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ## Configuration\n",
    "@dataclass\n",
    "class EvalConfig:\n",
    "    \"\"\"Configuration for the evaluation system.\"\"\"\n",
    "    model_names: List[str]\n",
    "    evaluation_method: int  # 1 for numeric, 2 for ranking\n",
    "    use_subset_evaluation: bool\n",
    "    evaluators_subset_size: int\n",
    "    output_dir: Path\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if self.evaluation_method not in {1, 2}:\n",
    "            raise ValueError(\"evaluation_method must be 1 or 2\")\n",
    "        if self.evaluators_subset_size >= len(self.model_names):\n",
    "            raise ValueError(\"evaluators_subset_size must be less than number of models\")\n",
    "\n",
    "# Default configuration\n",
    "DEFAULT_CONFIG = EvalConfig(\n",
    "    model_names=[\n",
    "        \"gemini-2.0-flash-thinking-exp-1219\",\n",
    "        \"gemini-exp-1206\",\n",
    "        \"claude-3-5-sonnet-latest\",\n",
    "        \"claude-3-opus-latest\",\n",
    "        \"o1-preview\",\n",
    "        \"gpt-4o\",\n",
    "        \"deepseek-chat\"\n",
    "    ],\n",
    "    evaluation_method=1,\n",
    "    use_subset_evaluation=True,\n",
    "    evaluators_subset_size=3,\n",
    "    output_dir=Path(\"results\")\n",
    ")\n",
    "\n",
    "# ## Core Evaluation Classes\n",
    "class ResponseManager:\n",
    "    \"\"\"Handles model response collection and validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EvalConfig):\n",
    "        self.config = config\n",
    "        self.responses_df = None\n",
    "        \n",
    "    def _validate_response(self, response: str) -> bool:\n",
    "        \"\"\"Basic validation of model responses.\"\"\"\n",
    "        if not isinstance(response, str):\n",
    "            return False\n",
    "        if len(response.strip()) < 10:  # Arbitrary minimum length\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def collect_responses(self, prompts: List[str], llm_module) -> pd.DataFrame:\n",
    "        \"\"\"Collect responses from all models for given prompts.\"\"\"\n",
    "        responses = []\n",
    "        total_start = time.time()\n",
    "        \n",
    "        for i, prompt in enumerate(prompts, 1):\n",
    "            logger.info(f\"Processing prompt {i}/{len(prompts)}\")\n",
    "            for model_name in self.config.model_names:\n",
    "                start_time = time.time()\n",
    "                logger.info(f\"Querying {model_name}...\")\n",
    "                try:\n",
    "                    model = llm_module.get_model(model_name)\n",
    "                    response = model.prompt(prompt).text()\n",
    "                    is_valid = self._validate_response(response)\n",
    "                    elapsed = time.time() - start_time\n",
    "                    \n",
    "                    logger.info(f\"{model_name} responded in {elapsed:.2f}s - \" + \n",
    "                              f\"{'Valid' if is_valid else 'Invalid'} response\")\n",
    "                    \n",
    "                    responses.append({\n",
    "                        'prompt': prompt,\n",
    "                        'model': model_name,\n",
    "                        'response': response if is_valid else None,\n",
    "                        'is_valid': is_valid,\n",
    "                        'response_time': elapsed\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    logger.error(f\"Error from {model_name} after {elapsed:.2f}s: {str(e)}\")\n",
    "                    responses.append({\n",
    "                        'prompt': prompt,\n",
    "                        'model': model_name,\n",
    "                        'response': None,\n",
    "                        'is_valid': False,\n",
    "                        'response_time': elapsed\n",
    "                    })\n",
    "                    \n",
    "                # Add a small delay between requests to avoid rate limits\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "        total_time = time.time() - total_start\n",
    "        logger.info(f\"All responses collected in {total_time:.2f}s\")\n",
    "        \n",
    "        self.responses_df = pd.DataFrame(responses)\n",
    "        return self.responses_df\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"Handles the evaluation of model responses.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EvalConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def _create_evaluation_prompt(self, \n",
    "                                prompt: str, \n",
    "                                responses: Dict[str, str]) -> Tuple[str, Dict[str, str]]:\n",
    "        \"\"\"Creates the evaluation prompt and model mappings.\"\"\"\n",
    "        model_to_anonymous = {\n",
    "            model: f\"Model_{i+1}\" \n",
    "            for i, model in enumerate(responses.keys())\n",
    "        }\n",
    "        \n",
    "        answers_section = \"\\n\".join([\n",
    "            f\"{model_to_anonymous[model]}:\\n{response}\\n---\" \n",
    "            for model, response in responses.items()\n",
    "        ])\n",
    "        \n",
    "        if self.config.evaluation_method == 1:\n",
    "            instructions = f\"\"\"IMPORTANT: Return only a JSON object with ratings.\n",
    "            \n",
    "            Rate these responses to: \"{prompt}\"\n",
    "\n",
    "            {answers_section}\n",
    "\n",
    "            Rate 1-10 based on: accuracy, completeness, clarity, relevance, depth, usefulness\n",
    "            10: Exceptional, 8-9: Excellent, 6-7: Good, 4-5: Fair, 1-3: Poor\n",
    "\n",
    "            Format: {{\"Model_1\": 8, \"Model_2\": 7}}\"\"\"\n",
    "        else:\n",
    "            instructions = f\"\"\"IMPORTANT: Return only a JSON object with rankings.\n",
    "            \n",
    "            Rank these responses to: \"{prompt}\"\n",
    "\n",
    "            {answers_section}\n",
    "\n",
    "            Rank from best (1) to worst. No ties allowed.\n",
    "            Consider: accuracy, completeness, clarity, relevance, depth, usefulness\n",
    "\n",
    "            Format: {{\"Model_1\": 1, \"Model_2\": 2}}\"\"\"\n",
    "            \n",
    "        return instructions.strip(), model_to_anonymous\n",
    "    \n",
    "    def _parse_evaluation(self, \n",
    "                         raw_judgment: str, \n",
    "                         model_mapping: Dict[str, str]) -> Dict[str, float]:\n",
    "        \"\"\"Parse and validate evaluation responses.\"\"\"\n",
    "        try:\n",
    "            # Extract JSON object\n",
    "            start = raw_judgment.find(\"{\")\n",
    "            end = raw_judgment.rfind(\"}\") + 1\n",
    "            if start == -1 or end == 0:\n",
    "                raise ValueError(\"No JSON object found\")\n",
    "            \n",
    "            data = json.loads(raw_judgment[start:end])\n",
    "            \n",
    "            # Convert anonymous IDs back to real model names\n",
    "            anonymous_to_model = {v: k for k, v in model_mapping.items()}\n",
    "            results = {}\n",
    "            \n",
    "            for anon_id, score in data.items():\n",
    "                model = anonymous_to_model.get(anon_id)\n",
    "                if not model:\n",
    "                    continue\n",
    "                    \n",
    "                if self.config.evaluation_method == 1:\n",
    "                    # Numeric scores\n",
    "                    score = float(score)\n",
    "                    score = max(1.0, min(10.0, score))\n",
    "                else:\n",
    "                    # Rankings\n",
    "                    score = int(score)\n",
    "                \n",
    "                results[model] = score\n",
    "                \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing evaluation: {str(e)}\")\n",
    "            # Return neutral scores\n",
    "            return {\n",
    "                model: 5.0 if self.config.evaluation_method == 1 else len(model_mapping)\n",
    "                for model in model_mapping.keys()\n",
    "            }\n",
    "\n",
    "    def evaluate_responses(self, \n",
    "                         responses_df: pd.DataFrame,\n",
    "                         llm_module) -> Tuple[nx.DiGraph, pd.DataFrame]:\n",
    "        \"\"\"Evaluate all responses and build the graph.\"\"\"\n",
    "        G = nx.DiGraph()\n",
    "        G.add_nodes_from(self.config.model_names)\n",
    "        \n",
    "        evaluations = []\n",
    "        \n",
    "        for prompt in responses_df['prompt'].unique():\n",
    "            prompt_responses = responses_df[\n",
    "                responses_df['prompt'] == prompt\n",
    "            ].set_index('model')['response'].to_dict()\n",
    "            \n",
    "            # For each judge model\n",
    "            for judge_model in self.config.model_names:\n",
    "                # Select models to evaluate\n",
    "                other_models = [\n",
    "                    m for m in self.config.model_names \n",
    "                    if m != judge_model and prompt_responses.get(m) is not None\n",
    "                ]\n",
    "                \n",
    "                if self.config.use_subset_evaluation:\n",
    "                    other_models = random.sample(\n",
    "                        other_models,\n",
    "                        min(self.config.evaluators_subset_size, len(other_models))\n",
    "                    )\n",
    "                \n",
    "                if not other_models:\n",
    "                    continue\n",
    "                \n",
    "                # Create evaluation prompt\n",
    "                eval_prompt, model_mapping = self._create_evaluation_prompt(\n",
    "                    prompt,\n",
    "                    {m: prompt_responses[m] for m in other_models}\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    # Get evaluation from judge\n",
    "                    raw_judgment = llm_module.get_model(judge_model).prompt(eval_prompt).text()\n",
    "                    parsed_judgments = self._parse_evaluation(raw_judgment, model_mapping)\n",
    "                    \n",
    "                    # Record evaluations\n",
    "                    for rated_model, score in parsed_judgments.items():\n",
    "                        evaluations.append({\n",
    "                            'prompt': prompt,\n",
    "                            'judge_model': judge_model,\n",
    "                            'rated_model': rated_model,\n",
    "                            'score': score\n",
    "                        })\n",
    "                        \n",
    "                        # Update graph\n",
    "                        if G.has_edge(judge_model, rated_model):\n",
    "                            G[judge_model][rated_model]['weight'] += score\n",
    "                        else:\n",
    "                            G.add_edge(judge_model, rated_model, weight=score)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error during evaluation: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        return G, pd.DataFrame(evaluations)\n",
    "\n",
    "class SlopRank:\n",
    "    \"\"\"Main class for running the evaluation pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EvalConfig = DEFAULT_CONFIG):\n",
    "        self.config = config\n",
    "        self.response_manager = ResponseManager(config)\n",
    "        self.evaluator = Evaluator(config)\n",
    "        \n",
    "    def run(self, prompts: List[str], llm_module) -> Dict:\n",
    "        \"\"\"Run the full evaluation pipeline.\"\"\"\n",
    "        # Collect responses\n",
    "        logger.info(\"Collecting responses...\")\n",
    "        responses_df = self.response_manager.collect_responses(prompts, llm_module)\n",
    "        \n",
    "        # Save responses\n",
    "        responses_path = self.config.output_dir / \"responses.csv\"\n",
    "        responses_df.to_csv(responses_path, index=False)\n",
    "        logger.info(f\"Saved responses to {responses_path}\")\n",
    "        \n",
    "        # Evaluate responses\n",
    "        logger.info(\"Evaluating responses...\")\n",
    "        G, evaluations_df = self.evaluator.evaluate_responses(responses_df, llm_module)\n",
    "        \n",
    "        # Calculate PageRank\n",
    "        if len(G.edges) == 0:\n",
    "            logger.error(\"No valid evaluations to compute PageRank\")\n",
    "            return {}\n",
    "            \n",
    "        pagerank_scores = nx.pagerank(G, weight=\"weight\")\n",
    "        ranked_models = sorted(\n",
    "            pagerank_scores.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            \"rankings\": ranked_models,\n",
    "            \"metadata\": {\n",
    "                \"evaluation_method\": self.config.evaluation_method,\n",
    "                \"use_subset_evaluation\": self.config.use_subset_evaluation,\n",
    "                \"evaluators_subset_size\": self.config.evaluators_subset_size,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save all artifacts\n",
    "        evaluations_df.to_csv(\n",
    "            self.config.output_dir / \"evaluations.csv\",\n",
    "            index=False\n",
    "        )\n",
    "        nx.write_gml(G, self.config.output_dir / \"endorsement_graph.gml\")\n",
    "        with open(self.config.output_dir / \"rankings.json\", \"w\") as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "            \n",
    "        return results\n",
    "\n",
    "# %%\n",
    "def main():\n",
    "    \"\"\"Example usage of SlopRank.\"\"\"\n",
    "    import llm  # Your LLM module import\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    logger.info(\"Starting SlopRank evaluation\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Read prompts\n",
    "        logger.info(\"Reading prompts from prompts.csv\")\n",
    "        prompts_df = pd.read_csv(\"prompts.csv\")\n",
    "        prompts = prompts_df[\"Questions\"].tolist()\n",
    "        # prompts = [prompts_df[\"Questions\"].iloc[2]]  # Use only select prompts - for testing\n",
    "        logger.info(f\"Loaded {len(prompts)} prompts\")\n",
    "        \n",
    "        # Initialize evaluation\n",
    "        config = DEFAULT_CONFIG\n",
    "        logger.info(f\"Using configuration: {config}\")\n",
    "        evaluator = SlopRank(config)\n",
    "        \n",
    "        # Run evaluation\n",
    "        results = evaluator.run(prompts, llm)\n",
    "        \n",
    "        # Print results\n",
    "        if results:\n",
    "            print(\"\\n=== Model Rankings ===\")\n",
    "            max_score = max(score for _, score in results[\"rankings\"])\n",
    "            for model, score in results[\"rankings\"]:\n",
    "                normalized_score = score / max_score * 10  # Normalize to 0-10 scale\n",
    "                print(f\"{model:30} {score:.4f} (normalized: {normalized_score:.2f})\")\n",
    "                \n",
    "            total_time = time.time() - start_time\n",
    "            logger.info(f\"Evaluation completed in {total_time:.2f}s\")\n",
    "        else:\n",
    "            logger.error(\"No results generated\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Older implementation: SlopRank\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import llm\n",
    "import networkx as nx\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "##############################################################################\n",
    "# 1. Configuration\n",
    "##############################################################################\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"gemini-2.0-flash-thinking-exp-1219\",\n",
    "    \"gemini-exp-1206\",\n",
    "    \"claude-3-5-sonnet-latest\",\n",
    "    \"claude-3-opus-latest\",\n",
    "    \"o1-preview\",\n",
    "    \"gpt-4o\",\n",
    "    \"deepseek-chat\"\n",
    "]\n",
    "\n",
    "model_objects = {m: llm.get_model(m) for m in MODEL_NAMES}\n",
    "\n",
    "EVALUATION_METHOD = 1  # 1 (numeric 1–10) or 2 (Best-to-Worst)\n",
    "USE_SUBSET_EVALUATION = True  # Toggle to use partial evaluation\n",
    "EVALUATORS_SUBSET_SIZE = 3  # If True, limit judges to evaluate a subset of models\n",
    "\n",
    "##############################################################################\n",
    "# 2. Prompting functions\n",
    "##############################################################################\n",
    "\n",
    "def query_model(prompt, model_name):\n",
    "    \"\"\"\n",
    "    Sends a prompt to a specified model via 'llm' and returns the response text.\n",
    "    \"\"\"\n",
    "    response = model_objects[model_name].prompt(prompt)\n",
    "    return response.text()\n",
    "\n",
    "def query_model_all(df, model_name):\n",
    "    \"\"\"\n",
    "    Query the chosen model for all prompts in the DataFrame and save responses.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    cleaned_prompts = df[\"prompt\"].str.strip().str.lower()\n",
    "    colname = f\"response_{model_name}\"\n",
    "    df[colname] = cleaned_prompts.map(lambda x: query_model(x, model_name))\n",
    "    print(f\"{model_name} processing time: {time.time() - t0:.2f}s\")\n",
    "\n",
    "    # Ensure the 'responses' directory exists\n",
    "    os.makedirs(\"responses\", exist_ok=True)\n",
    "    \n",
    "    # Save responses for this model\n",
    "    response_file_path = f\"responses/responses_{model_name}.csv\"\n",
    "    df[[colname]].to_csv(response_file_path, index=False)\n",
    "    print(f\"Saved responses for {model_name} to {response_file_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def gather_all_model_responses(raw_prompts):\n",
    "    \"\"\"\n",
    "    Gather responses from all models and save to disk incrementally.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"prompt\": raw_prompts})\n",
    "    for m in MODEL_NAMES:\n",
    "        df = query_model_all(df, m)\n",
    "    return df\n",
    "\n",
    "##############################################################################\n",
    "# 3. Evaluate the responses\n",
    "##############################################################################\n",
    "\n",
    "def create_evaluation_mapping(other_models):\n",
    "    \"\"\"\n",
    "    Creates a mapping between model names and anonymous identifiers.\n",
    "    Returns both forward and reverse mappings.\n",
    "    \"\"\"\n",
    "    model_to_anonymous = {model: f\"Model_{i+1}\" for i, model in enumerate(other_models)}\n",
    "    anonymous_to_model = {v: k for k, v in model_to_anonymous.items()}\n",
    "    return model_to_anonymous, anonymous_to_model\n",
    "\n",
    "def build_evaluation_prompt(method, prompt, judge_model, model_responses, other_models):\n",
    "    \"\"\"\n",
    "    Build a meta-prompt.\n",
    "    \"\"\"\n",
    "    model_to_anonymous, _ = create_evaluation_mapping(other_models)\n",
    "    \n",
    "    answers_section = \"\\n\".join([\n",
    "        f\"{model_to_anonymous[om]}:\\n{model_responses[om]}\\n---\" \n",
    "        for om in other_models\n",
    "    ])\n",
    "\n",
    "    if method == 1:\n",
    "        instructions = f\"\"\"IMPORTANT: You must ONLY return a JSON object with ratings. No explanation or additional text.\n",
    "\n",
    "        You are an impartial judge able to analyse multiple responses to a prompt and give it an objective rating.\n",
    "\n",
    "        PROMPT TO EVALUATE:\n",
    "        \"{prompt}\"\n",
    "\n",
    "        RESPONSES TO RATE:\n",
    "        {answers_section}\n",
    "\n",
    "        RATING INSTRUCTIONS:\n",
    "        - Rate each response from 1 to 10\n",
    "        - Consider: accuracy, completeness, clarity, relevance, depth, usefulness\n",
    "        - 10: Exceptional, 8-9: Excellent, 6-7: Good, 4-5: Fair, 1-3: Poor\n",
    "\n",
    "        YOUR RESPONSE MUST BE EXACTLY IN THIS FORMAT:\n",
    "        {{\n",
    "            \"Model_1\": 8,\n",
    "            \"Model_2\": 7\n",
    "        }}\n",
    "\n",
    "        DO NOT include any other text, explanations, or analysis. ONLY the JSON object above.\"\"\"\n",
    "    else:\n",
    "        instructions = f\"\"\"IMPORTANT: You must ONLY return a JSON object with rankings. No explanation or additional text.\n",
    "\n",
    "        You are an impartial judge who will rank the given responses to a question objectvely.\n",
    "\n",
    "        PROMPT TO EVALUATE:\n",
    "        \"{prompt}\"\n",
    "\n",
    "        RESPONSES TO RANK:\n",
    "        {answers_section}\n",
    "\n",
    "        RANKING INSTRUCTIONS:\n",
    "        - Rank all responses from best to worst (1 = best, higher numbers = worse).\n",
    "        - Consider: accuracy, completeness, clarity, relevance, depth, usefulness.\n",
    "        - Do NOT assign the same rank to multiple responses (no ties).\n",
    "\n",
    "        YOUR RESPONSE MUST BE EXACTLY IN THIS FORMAT:\n",
    "        {{\n",
    "            \"Model_1\": 1,\n",
    "            \"Model_2\": 2,\n",
    "            \"Model_3\": 3\n",
    "        }}\n",
    "\n",
    "        DO NOT include any other text, explanations, or analysis. ONLY the JSON object above.\"\"\"\n",
    "\n",
    "    return instructions.strip(), model_to_anonymous\n",
    "\n",
    "def parse_evaluation_output(method, raw_judgment, anonymous_mapping):\n",
    "    \"\"\"\n",
    "    Enhanced parsing with better error handling and logging.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the input text more aggressively\n",
    "        cleaned_text = raw_judgment.strip()\n",
    "        # Find the first { and last }\n",
    "        start = cleaned_text.find(\"{\")\n",
    "        end = cleaned_text.rfind(\"}\") + 1\n",
    "        \n",
    "        if start == -1 or end == 0:\n",
    "            raise ValueError(\"No JSON object found in response\")\n",
    "            \n",
    "        json_str = cleaned_text[start:end]\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "    except (json.JSONDecodeError, ValueError) as e:\n",
    "        print(f\"Warning: Failed to parse judgment. Error: {str(e)}\")\n",
    "        print(f\"Raw response: {raw_judgment[:200]}...\")\n",
    "        # Return neutral fallback values\n",
    "        return {anonymous_mapping[k]: (5.0 if method == 1 else 0) for k in anonymous_mapping}\n",
    "\n",
    "    endorsement_map = {}\n",
    "    for anonymous_id, real_model in anonymous_mapping.items():\n",
    "        val = data.get(anonymous_id)\n",
    "        \n",
    "        if val is None:\n",
    "            print(f\"Warning: Missing rating for {anonymous_id}\")\n",
    "            endorsement_map[real_model] = 5.0 if method == 1 else 0\n",
    "            continue\n",
    "\n",
    "        if method == 1:\n",
    "            try:\n",
    "                score = float(val)\n",
    "                if not (1 <= score <= 10):\n",
    "                    print(f\"Warning: Score {score} for {anonymous_id} out of range, clamping to [1,10]\")\n",
    "                endorsement_map[real_model] = max(1.0, min(10.0, score))\n",
    "            except (TypeError, ValueError):\n",
    "                print(f\"Warning: Invalid numeric score for {anonymous_id}: {val}\")\n",
    "                endorsement_map[real_model] = 5.0\n",
    "        else:\n",
    "            if val is None:\n",
    "                print(f\"Warning: Missing rank for {anonymous_id}\")\n",
    "                endorsement_map[real_model] = len(anonymous_mapping)  # Assign worst rank\n",
    "            else:\n",
    "                try:\n",
    "                    endorsement_map[real_model] = int(val)\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Invalid rank for {anonymous_id}: {val}\")\n",
    "                    endorsement_map[real_model] = len(anonymous_mapping)  # Assign worst rank\n",
    "\n",
    "    return endorsement_map\n",
    "\n",
    "def evaluate_responses(df):\n",
    "    \"\"\"\n",
    "    Evaluate responses with improved error handling and DataFrame operations.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(MODEL_NAMES)\n",
    "\n",
    "    # Initialize DataFrame to store evaluations\n",
    "    evaluations_df = pd.DataFrame({\n",
    "        'prompt': [],\n",
    "        'judge_model': [],\n",
    "        'rated_model_anonymous': [],\n",
    "        'rated_model_real': [],\n",
    "        'rating': [],\n",
    "        'method': []\n",
    "    })\n",
    "\n",
    "    # Filter valid evaluations only\n",
    "    valid_evaluations = evaluations_df[evaluations_df['rating'].notnull()]\n",
    "    \n",
    "    if valid_evaluations.empty:\n",
    "        print(\"No valid evaluations found. Skipping PageRank calculation.\")\n",
    "        return G, []\n",
    "\n",
    "    # Iterate through prompts and evaluate responses\n",
    "    for idx, row in df.iterrows():\n",
    "        prompt = row[\"prompt\"]\n",
    "        model_responses = {m: row.get(f\"response_{m}\", \"No response\") for m in MODEL_NAMES}\n",
    "\n",
    "        for judge_model in MODEL_NAMES:\n",
    "            other_models = [m for m in MODEL_NAMES if m != judge_model]\n",
    "\n",
    "            # Use subset evaluation if enabled\n",
    "            if USE_SUBSET_EVALUATION and len(other_models) > EVALUATORS_SUBSET_SIZE:\n",
    "                other_models = random.sample(other_models, EVALUATORS_SUBSET_SIZE)\n",
    "\n",
    "            # Skip if no valid models to evaluate\n",
    "            if not other_models:\n",
    "                print(f\"Skipping evaluation for prompt: {prompt} (insufficient valid responses)\")\n",
    "                continue\n",
    "\n",
    "            # Build evaluation prompt\n",
    "            evaluation_prompt, model_to_anonymous = build_evaluation_prompt(\n",
    "                EVALUATION_METHOD, prompt, judge_model, model_responses, other_models\n",
    "            )\n",
    "            anonymous_to_model = {v: k for k, v in model_to_anonymous.items()}\n",
    "\n",
    "            # Query the judge model\n",
    "            raw_judgment = query_model(evaluation_prompt, judge_model)\n",
    "            parsed_judgments = parse_evaluation_output(\n",
    "                EVALUATION_METHOD, raw_judgment, anonymous_to_model\n",
    "            )\n",
    "\n",
    "            # Create a new DataFrame for this batch of evaluations\n",
    "            new_evaluations = []\n",
    "            for rated_model, endorsement_val in parsed_judgments.items():\n",
    "                anonymous_id = model_to_anonymous[rated_model]\n",
    "                new_evaluations.append({\n",
    "                    'prompt': prompt,\n",
    "                    'judge_model': judge_model,\n",
    "                    'rated_model_anonymous': anonymous_id,\n",
    "                    'rated_model_real': rated_model,\n",
    "                    'rating': endorsement_val,\n",
    "                    'method': EVALUATION_METHOD\n",
    "                })\n",
    "            \n",
    "            # Concatenate efficiently\n",
    "            if new_evaluations:\n",
    "                evaluations_df = pd.concat([\n",
    "                    evaluations_df, \n",
    "                    pd.DataFrame(new_evaluations)\n",
    "                ], ignore_index=True)\n",
    "\n",
    "            # Update graph with valid ratings\n",
    "            for rated_model, endorsement_val in parsed_judgments.items():\n",
    "                if G.has_edge(judge_model, rated_model):\n",
    "                    G[judge_model][rated_model][\"weight\"] += endorsement_val\n",
    "                else:\n",
    "                    G.add_edge(judge_model, rated_model, weight=endorsement_val)\n",
    "\n",
    "    # Compute PageRank only if the graph has valid edges\n",
    "    if len(G.edges) == 0:\n",
    "        print(\"Graph has no valid edges. Cannot compute PageRank.\")\n",
    "        return G, []\n",
    "\n",
    "    pagerank_scores = nx.pagerank(G, weight=\"weight\")\n",
    "    ranked_models = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Save all data\n",
    "    nx.write_gml(G, \"responses/endorsement_graph.gml\")\n",
    "    print(\"Saved endorsement graph to endorsement_graph.gml\")\n",
    "\n",
    "    evaluations_df.to_csv(\"responses/evaluations_with_mapping.csv\", index=False)\n",
    "    print(\"Saved detailed evaluations with mappings to evaluations_with_mapping.csv\")\n",
    "\n",
    "    with open(\"rankings.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"rankings\": ranked_models,\n",
    "            \"metadata\": {\n",
    "                \"evaluation_method\": EVALUATION_METHOD,\n",
    "                \"use_subset_evaluation\": USE_SUBSET_EVALUATION,\n",
    "                \"evaluators_subset_size\": EVALUATORS_SUBSET_SIZE,\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "        }, f, indent=4)\n",
    "    print(\"Saved rankings to rankings.json\")\n",
    "\n",
    "    return G, ranked_models\n",
    "\n",
    "##############################################################################\n",
    "# 4. Main\n",
    "##############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prompts_df = pd.read_csv(\"prompts.csv\")  # Assuming the CSV has a column named \"Questions\"\n",
    "    raw_prompts = prompts_df[\"Questions\"].tolist()\n",
    "    # raw_prompts = [prompts_df[\"Questions\"].iloc[2]]  # Use only select prompts - for testing\n",
    "\n",
    "    # Gather responses for each model\n",
    "    df_responses = gather_all_model_responses(raw_prompts)\n",
    "\n",
    "    # Evaluate responses and compute rankings\n",
    "    G, ranked = evaluate_responses(df_responses)\n",
    "\n",
    "    print(\"\\n=== PageRank Scores ===\")\n",
    "    for model, score in ranked:\n",
    "        print(f\"{model}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
